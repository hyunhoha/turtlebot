turtlebot3_navigation node

/odom = 로봇 기반 Pose (0,0) 기준으로 시작함
/amcl_pose = navigation할 때 지도 기준 절대위치

/amcl_pose는 amcl 노드에서 publish됨.

amcl node 코드 : 
http://wiki.ros.org/amcl에서 찾아보면
https://github.com/ros-planning/navigation/blob/noetic-devel/amcl/src/amcl_node.cpp

<amcl_pose Publish하는 부분>

pose_pub_ = nh_.advertise<geometry_msgs::PoseWithCovarianceStamped>("amcl_pose", 2, true);

geometry_msgs::PoseWithCovarianceStamped p;
      // Fill in the header
      p.header.frame_id = global_frame_id_;
      p.header.stamp = laser_scan->header.stamp;
      // Copy in the pose
      p.pose.pose.position.x = hyps[max_weight_hyp].pf_pose_mean.v[0];
      p.pose.pose.position.y = hyps[max_weight_hyp].pf_pose_mean.v[1];

      tf2::Quaternion q;
      q.setRPY(0, 0, hyps[max_weight_hyp].pf_pose_mean.v[2]);
      tf2::convert(q, p.pose.pose.orientation);
      // Copy in the covariance, converting from 3-D to 6-D
      pf_sample_set_t* set = pf_->sets + pf_->current_set;
      for(int i=0; i<2; i++)
      {
        for(int j=0; j<2; j++)
        {
          // Report the overall filter covariance, rather than the
          // covariance for the highest-weight cluster
          //p.covariance[6*i+j] = hyps[max_weight_hyp].pf_pose_cov.m[i][j];
          p.pose.covariance[6*i+j] = set->cov.m[i][j];
        }
      }
      // Report the overall filter covariance, rather than the
      // covariance for the highest-weight cluster
      //p.covariance[6*5+5] = hyps[max_weight_hyp].pf_pose_cov.m[2][2];
      p.pose.covariance[6*5+5] = set->cov.m[2][2];

      /*
         printf("cov:\n");
         for(int i=0; i<6; i++)
         {
         for(int j=0; j<6; j++)
         printf("%6.3f ", p.covariance[6*i+j]);
         puts("");
         }
       */

      pose_pub_.publish(p);
      

amcl_hyp_t -> weight, mean of pose, covariance of pose estimate

amcl_pose 계산 = Laser scan 받은거 기반으로 함.

따라서, laser 기반 위치인식을 하는데 바퀴 위치가 달라서 실제 로봇의 이동 위치와 laser 기반 추정 위치의 오차가 발생함.

로봇의 바퀴 위치만 바꿨는데 Laser Scan이 이상하게 뜸.. 

-> amcl node에서 messagefilter를 사용해서 laser_scan을 처리함.

// Helper to get odometric pose from transform system
    bool getOdomPose(geometry_msgs::PoseStamped& pose,
                     double& x, double& y, double& yaw,
                     const ros::Time& t, const std::string& f);
                     
+ odom 전처리
AmclNode::getOdomPose(geometry_msgs::PoseStamped& odom_pose,
                      double& x, double& y, double& yaw,
                      const ros::Time& t, const std::string& f)
{
  // Get the robot's pose
  geometry_msgs::PoseStamped ident;
  ident.header.frame_id = stripSlash(f);
  ident.header.stamp = t;
  tf2::toMsg(tf2::Transform::getIdentity(), ident.pose);
  try
  {
    this->tf_->transform(ident, odom_pose, odom_frame_id_);
  }
  catch(tf2::TransformException e)
  {
    ROS_WARN("Failed to compute odom pose, skipping scan (%s)", e.what());
    return false;
  }
  x = odom_pose.pose.position.x;
  y = odom_pose.pose.position.y;
  yaw = tf2::getYaw(odom_pose.pose.orientation);

  return true;
}

odom transformation의 사용

// Where was the robot when this scan was taken?
if(!getOdomPose(latest_odom_pose_, pose.v[0], pose.v[1], pose.v[2],
                  laser_scan->header.stamp, base_frame_id_))
  {
    ROS_ERROR("Couldn't determine robot's pose associated with laser scan");
    return;
  }

odom도 laser scan 기반으로 추정..

laser scan의 오측정 이유 : Turtlebot3가 기울어져 바닥을 벽으로 인식하게 된 것.

<실제 로봇 형태에 맞게 urdf파일 수정 반영하기>

urdf file 변경 (실제 로봇 형태에 맞게)
turtlebot3_burger_wheel_changed.urdf.xacro
turtlebot3_burger_wheel_changed.gazebo.xacro
두 개의 변경된 파일 저장

$ roscd turtlebot3_bringup
여기서, include/description.launch.xml 파일에서 wheel_changed urdf 파일로 수정
